{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f0f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # type: ignore\n",
    "import numpy as np  # type: ignore\n",
    "\n",
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "from matplotlib.ticker import MaxNLocator  # type: ignore\n",
    "\n",
    "from sklearn.manifold import TSNE  # type: ignore\n",
    "from sklearn.decomposition import PCA  # type: ignore\n",
    "from sklearn.preprocessing import StandardScaler  # type: ignore\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # type: ignore\n",
    "from sklearn.linear_model import LinearRegression  # type: ignore\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "SEED = 42\n",
    "s = 1000\n",
    "\n",
    "def get_darth_results_path(ds_name, k, nlist, nprobe, qs, tr, ipi, mpi):\n",
    "    return f\"/home/mchatzakis/cfaiss/experiments/ivf-results/darth/{ds_name}/k{k}/nlist{nlist}_nprobe{nprobe}_qs{qs}_tr{float(tr):.2f}_ipi{ipi}_mpi{mpi}.txt\"\n",
    "\n",
    "def get_plain_ivf_results_path(ds_name, k, nlist, nprobe, qs):\n",
    "    return f\"/home/mchatzakis/cfaiss/experiments/ivf-results/plain-ivf/testing/{ds_name}/k{k}/nlist{nlist}_nprobe{nprobe}_qs{qs}.txt\"\n",
    "\n",
    "def get_detailed_testing_queries_results_path(ds_name, k, nlist, nprobe, qs, li):\n",
    "    return f\"/data/mchatzakis/et_training_data/ivf/training-data-generation/testing/{ds_name}/{k}/nlist{nlist}_nprobe{nprobe}_qs{qs}_li{li}.txt\"\n",
    "\n",
    "def get_darth_model_path(ds_name, nlist, nprobe, s, k, li):\n",
    "    return f\"/home/mchatzakis/cfaiss/predictor_models/ivf/darth/{ds_name}_nlist{nlist}_nprobe{nprobe}_s{s}_k{k}_nestim100_lr0.1_li{li}_rl0_all_feats.txt\"\n",
    "\n",
    "dataset_params = {\n",
    "        \"SIFT100M\": {\n",
    "            \"M\": 32,\n",
    "            \"efC\": 500,\n",
    "            \"efS\": 500,\n",
    "            \"color\": \"lightblue\",\n",
    "            \"marker\": \"o\",\n",
    "            \"li\": 1,\n",
    "            \"label\": \"SIFT100M\",\n",
    "            \"ivf_li\": 50,\n",
    "            \"nlist\": 10000,\n",
    "            \"nprobe\": 150,\n",
    "        },\n",
    "        \"DEEP100M\": {\n",
    "            \"M\": 32,\n",
    "            \"efC\": 500,\n",
    "            \"efS\": 750,\n",
    "            \"color\": \"plum\",\n",
    "            \"marker\": \"x\",   \n",
    "            \"li\": 1,\n",
    "            \"label\": \"DEEP100M\",\n",
    "            \"ivf_li\": 50,\n",
    "            \"nlist\": 10000,\n",
    "            \"nprobe\": 150,\n",
    "        },\n",
    "        \"GLOVE100\": {\n",
    "            \"M\": 16,\n",
    "            \"efC\": 500,\n",
    "            \"efS\": 500,\n",
    "            \"color\": \"orange\",\n",
    "            \"marker\": \"^\",\n",
    "            \"li\": 1,\n",
    "            \"label\": \"GLOVE1M\",\n",
    "            \"ivf_li\": 20,\n",
    "            \"nlist\": 1000,\n",
    "            \"nprobe\": 100,\n",
    "        },\n",
    "        \"GIST1M\": {\n",
    "            \"M\": 32,\n",
    "            \"efC\": 500,\n",
    "            \"efS\": 1000,\n",
    "            \"color\": \"lightgreen\",\n",
    "            \"marker\": \"s\",\n",
    "            \"li\": 1,\n",
    "            \"label\": \"GIST1M\",\n",
    "            \"ivf_li\": 20,\n",
    "            \"nlist\": 1000,\n",
    "            \"nprobe\": 200,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "PLOTS_DIR = \"./../../experiments/ivf-revision-plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f6304",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "n_estimators = 100\n",
    "\n",
    "index_metric_feats = [\"step\", \"dists\", \"inserts\"]\n",
    "neighbor_distances_feats = [\"first_nn_dist\", \"nn_dist\", \"furthest_dist\"]\n",
    "neighbor_stats_feats = [\"avg_dist\", \"variance\", \"percentile_25\", \"percentile_50\", \"percentile_75\"]\n",
    "all_feats = index_metric_feats + neighbor_distances_feats + neighbor_stats_feats\n",
    "\n",
    "columns_to_load = [\"qid\", \"elaps_ms\"] + all_feats + [\"r\", \"feats_collect_time_ms\"]\n",
    "\n",
    "feature_classes = {\n",
    "    #\"index_metric_feats\": index_metric_feats,\n",
    "    #\"neighbor_distances_feats\": neighbor_distances_feats,\n",
    "    #\"neighbor_stats_feats\": neighbor_stats_feats,\n",
    "    #\"index_metrics_and_neighbor_distances\": index_metric_feats + neighbor_distances_feats,\n",
    "    #\"index_metrics_and_neighbor_stats\": index_metric_feats + neighbor_stats_feats,\n",
    "    #\"neighbor_distances_and_neighbor_stats\": neighbor_distances_feats + neighbor_stats_feats,\n",
    "    \"all_feats\": all_feats,\n",
    "}\n",
    "\n",
    "\n",
    "all_k_values = [\"50\"]\n",
    "all_datasets = [\"SIFT100M\", \"DEEP100M\", \"GLOVE100\", \"GIST1M\"]\n",
    "\n",
    "for ds_name in all_datasets:\n",
    "    mse_per_k = []\n",
    "    mae_per_k = []\n",
    "    r2_per_k = []\n",
    "    max_error_per_k = []\n",
    "    \n",
    "    nlist = dataset_params[ds_name][\"nlist\"]\n",
    "    nprobe = dataset_params[ds_name][\"nprobe\"]\n",
    "    li = dataset_params[ds_name][\"ivf_li\"]\n",
    "    \n",
    "    for k in all_k_values:\n",
    "        feats = all_feats\n",
    "        model_file = get_darth_model_path(ds_name, nlist, nprobe, 10000, k, li)\n",
    "        model = lgb.Booster(model_file=model_file)\n",
    "        \n",
    "        testing_data_df_dask = dd.read_csv(get_detailed_testing_queries_results_path(ds_name, k, nlist, nprobe, 1000, li), usecols=columns_to_load)\n",
    "        testing_data_df = testing_data_df_dask.compute()\n",
    "        testing_y_true = testing_data_df[\"r\"]            \n",
    "                    \n",
    "        validation_X = testing_data_df[feats]\n",
    "        validation_y_pred = model.predict(validation_X)\n",
    "        mse = mean_squared_error(testing_y_true, validation_y_pred)\n",
    "        mae = mean_absolute_error(testing_y_true, validation_y_pred)\n",
    "        r2 = r2_score(testing_y_true, validation_y_pred)\n",
    "        max_error = np.max(np.abs(testing_y_true - validation_y_pred))\n",
    "        \n",
    "        mse_per_k.append(mse)\n",
    "        mae_per_k.append(mae)\n",
    "        r2_per_k.append(r2)\n",
    "        max_error_per_k.append(max_error)\n",
    "        \n",
    "        #print(f\"    {ds_name} k={k} => mse: {mse:.4f}, mae: {mae:.4f}, r2: {r2:.4f}\")\n",
    "\n",
    "    mse_ds = np.mean(mse_per_k)\n",
    "    mae_ds = np.mean(mae_per_k)\n",
    "    r2_ds = np.mean(r2_per_k)\n",
    "    max_error_ds = np.mean(max_error_per_k)\n",
    "    \n",
    "    print(f\"{ds_name} => mse: {mse_ds:.4f}, mae: {mae_ds:.4f}, r2: {r2_ds:.2f}\")\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataconf from a file:\n",
    "IPI_DIV = 2\n",
    "MPI_DIV = 10\n",
    "interval_conf = {}\n",
    "with open(f\"../../experiments/generated_json/ivf/ivf_darth_params_ipi{IPI_DIV}_mpi{MPI_DIV}.json\") as f:\n",
    "    interval_conf = json.load(f)\n",
    "print(interval_conf.keys(), interval_conf[\"SIFT100M\"].keys(), interval_conf[\"SIFT100M\"][\"50\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58856b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate for all datasets and all k-s the average recall vs the target recall\n",
    "all_datasets = [\"SIFT100M\", \"DEEP100M\", \"GLOVE100\", \"GIST1M\"]\n",
    "all_k_values = [\"50\"]\n",
    "all_r_targets = [\"0.8\", \"0.85\", \"0.9\", \"0.95\", \"0.99\"]\n",
    "\n",
    "all_speedups = [] #meant to extract analytics\n",
    "\n",
    "ds_recalls = {} # k -> dataset -> [recall, std, qut, speedup for each r_target]\n",
    "\n",
    "for k in all_k_values:\n",
    "    ds_recalls[k] = {}\n",
    "    print(f\"k: {k}\")\n",
    "    for ds_name in all_datasets:\n",
    "        nlist = dataset_params[ds_name][\"nlist\"]\n",
    "        nprobe = dataset_params[ds_name][\"nprobe\"]\n",
    "        li = dataset_params[ds_name][\"ivf_li\"]\n",
    "        print(f\"    Dataset: {ds_name}\")\n",
    "        ds_recalls[k][ds_name] = []\n",
    "        \n",
    "        for r_target in all_r_targets:\n",
    "            ipi = interval_conf[ds_name][k][r_target][\"ipi\"]\n",
    "            mpi = interval_conf[ds_name][k][r_target][\"mpi\"]\n",
    "            r_target = float(r_target)\n",
    "                \n",
    "            #print(f\"r_target: {r_target}, ipi: {ipi}, mpi: {mpi}\")\n",
    "                \n",
    "            no_early_termination_df = pd.read_csv(get_plain_ivf_results_path(ds_name, k, nlist, nprobe, 1000), usecols=[\"qid\", \"step\", \"dists\", \"inserts\", \"elaps_ms\", \"r\"])\n",
    "            darth_df = pd.read_csv(get_darth_results_path(ds_name, k, nlist, nprobe, 1000, r_target, ipi, mpi), usecols=[\"qid\", \"step\", \"dists\", \"inserts\", \"elaps_ms\", \"r_actual\", \"r_predicted\", \"r_predictor_calls\", \"r_predictor_time_ms\",])\n",
    "            \n",
    "            no_early_termination_df = no_early_termination_df[no_early_termination_df[\"r\"] >= r_target]\n",
    "            darth_df = darth_df[darth_df[\"qid\"].isin(no_early_termination_df[\"qid\"])]\n",
    "            \n",
    "            darth_recall_avg = darth_df[\"r_actual\"].mean()\n",
    "            darth_recall_std = darth_df[\"r_actual\"].std()\n",
    "            darth_df[\"r_actual\"] = darth_df[\"r_actual\"].apply(lambda x: round(x, 2))\n",
    "            darth_rqut = len(darth_df[darth_df[\"r_actual\"] < r_target])\n",
    "            \n",
    "            speedup = no_early_termination_df[\"elaps_ms\"].mean() / darth_df[\"elaps_ms\"].mean()\n",
    "            \n",
    "            per_query_speedups = no_early_termination_df[\"elaps_ms\"] / darth_df[\"elaps_ms\"]\n",
    "            speedup_v2 = per_query_speedups.mean()\n",
    "            \n",
    "            all_speedups.append(speedup_v2)\n",
    "            \n",
    "            ds_recalls[k][ds_name].append([darth_recall_avg, darth_recall_std, darth_rqut, speedup, speedup_v2])\n",
    "            \n",
    "            print(f\"        r_target: {r_target}, darth_recall_avg: {darth_recall_avg:.4f}, darth_recall_std: {darth_recall_std:.4f}, darth_rqut: {darth_rqut}, speedup_v2: {speedup_v2:.2f}x\")            \n",
    "\n",
    "print(f\"Overall average speedup: {np.mean(all_speedups):.2f}x\")\n",
    "print(f\"Overall median speedup: {np.median(all_speedups):.2f}x\")\n",
    "print(f\"Max speedup: {np.max(all_speedups):.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = [\"SIFT100M\", \"DEEP100M\", \"GLOVE100\", \"GIST1M\"]\n",
    "all_k_values = [\"50\"]\n",
    "all_r_targets = [\"0.8\", \"0.85\", \"0.9\", \"0.95\", \"0.99\"]\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 40})\n",
    "\n",
    "fig_legend, ax_legend = plt.subplots(figsize=(8, 1))\n",
    "legend_elements = [Patch(facecolor=dataset_params[ds_name][\"color\"], edgecolor=dataset_params[ds_name][\"color\"], alpha=0.8, label=ds_name) for ds_name in [\"SIFT100M\", \"DEEP100M\", \"GLOVE100\", \"GIST1M\"]]\n",
    "ax_legend.legend(handles=legend_elements, loc='center', ncol=4, frameon=False, handletextpad=0.3,  columnspacing=0.5, labelspacing=0.3 )\n",
    "ax_legend.axis('off')\n",
    "fig_legend.savefig(f\"{PLOTS_DIR}summary_speedups_legend_only.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close(fig_legend)\n",
    "\n",
    "for k in all_k_values:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bar_width = 0.2\n",
    "    x = np.arange(len(all_r_targets))\n",
    "    for i, ds_name in enumerate(all_datasets):\n",
    "        recalls = []\n",
    "        x_positions = x + i * bar_width\n",
    "\n",
    "        for j, r_target in enumerate(all_r_targets):\n",
    "            recall = ds_recalls[k][ds_name][j][0]\n",
    "            recall_std = ds_recalls[k][ds_name][j][1]\n",
    "            recalls.append(recall)\n",
    "            std = recall_std\n",
    "            ax.bar(x_positions[j], recall, bar_width, color=dataset_params[ds_name][\"color\"], alpha=0.8, edgecolor='black', linewidth=2)\n",
    "            \n",
    "    ax.set_xticks(x + (len(all_datasets) - 1) * bar_width / 2)\n",
    "    ax.set_yticks([float(r) for r in [0.80, 0.85, 0.90, 0.95, 0.99]])\n",
    "    x_tick_labels = [\"0.80\", \"0.85\", \"0.90\", \"0.95\", \"0.99\"]\n",
    "    ax.set_xticklabels(x_tick_labels)\n",
    "    ax.set_xlabel(r\"$R_t$\")\n",
    "    ax.set_ylabel(\"Actual Recall\")\n",
    "    #ax.set_xticklabels([str(t) for t in all_r_targets])\n",
    "    ax.grid(alpha=0.8, axis='y', linestyle='--')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    ax.set_ylim(0.78, 1.00)\n",
    "    #ax.tick_params(axis='x', labelsize=38)\n",
    "    fig.tight_layout()\n",
    "    savepath = f\"{PLOTS_DIR}summary_recall_vs_target_recall_k{k}.pdf\"\n",
    "    fig.savefig(savepath, bbox_inches='tight')\n",
    "    print(f\"Fig saved at {savepath}\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # SPEEDUP PLOT\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bar_width = 0.2\n",
    "    x = np.arange(len(all_r_targets))\n",
    "    max_speedup = -1\n",
    "    for i, ds_name in enumerate(all_datasets):\n",
    "        x_positions = x + i * bar_width\n",
    "        speedup_version_to_use=4\n",
    "        speedups = []\n",
    "        for j, r_target in enumerate(all_r_targets):\n",
    "            speedup = ds_recalls[k][ds_name][j][speedup_version_to_use]\n",
    "            if speedup > max_speedup:\n",
    "                max_speedup = speedup\n",
    "            speedups.append(speedup)\n",
    "            ax.bar(x_positions[j], speedup, bar_width, color=dataset_params[ds_name][\"color\"], alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    ax.set_xticks(x + (len(all_datasets) - 1) * bar_width / 2)\n",
    "    ax.set_xlabel(r\"$R_t$\")\n",
    "    ax.set_ylabel(\"Times Faster\")\n",
    "    ax.set_yticks([10, 20, 30, 40])\n",
    "    #ax.set_yticks(np.arange(1, max_speedup + 1, 5))\n",
    "    ax.set_ylim(bottom=1)\n",
    "    x_tick_labels = [\"0.80\", \"0.85\", \"0.90\", \"0.95\", \"0.99\"]\n",
    "    ax.set_xticklabels(x_tick_labels)\n",
    "    ax.grid(alpha=0.8, axis='y', linestyle='--')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    #ax.tick_params(axis='x', labelsize=38)\n",
    "    fig.tight_layout()\n",
    "    filename = f\"{PLOTS_DIR}summary_speedup_vs_target_recall_k{k}.pdf\"\n",
    "    fig.savefig(filename, bbox_inches='tight')\n",
    "    print(f\"Fig saved at {filename}\")\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 40}) \n",
    "\n",
    "fig_legend, ax_legend = plt.subplots(figsize=(8, 1))  # Adjust the figsize for better alignment\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"tomato\", edgecolor=\"tomato\", alpha=0.8, label=\"DARTH\"),\n",
    "    Patch(facecolor=\"dimgray\", edgecolor=\"dimgray\", alpha=0.8, label=\"plain HNSW\"),\n",
    "    #Line2D([0], [0], color=\"tomato\", linestyle=\"dashed\", linewidth=5, label=\"DARTH Avg.\"),\n",
    "    #Line2D([0], [0], color=\"dimgray\", linestyle=\"dashed\", linewidth=5, label=\"HNSW No Early Termination Avg.\"),\n",
    "    #Line2D([0], [0], color=\"black\", linestyle=\"dashed\", linewidth=5, label=r\"$R_t$\"), \n",
    "]\n",
    "ax_legend.legend(handles=legend_elements, loc='center', ncol=5, frameon=False)\n",
    "\n",
    "ax_legend.axis('off')\n",
    "#fig_legend.savefig(f\"{PLOTS_DIR}perf_legend_only.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close(fig_legend)\n",
    "\n",
    "s = 1000\n",
    "all_datasets = [\"SIFT100M\", \"DEEP100M\", \"GLOVE100\", \"GIST1M\"]\n",
    "all_k_values = [\"50\"]\n",
    "for ds_name in all_datasets:\n",
    "    for k in all_k_values:\n",
    "        nlist = dataset_params[ds_name][\"nlist\"]\n",
    "        nprobe = dataset_params[ds_name][\"nprobe\"]\n",
    "        li = dataset_params[ds_name][\"ivf_li\"]\n",
    "        r_targets = interval_conf[ds_name][k].keys()\n",
    "\n",
    "        #if ds_name == \"T2I100M\":\n",
    "        #    r_targets = [\"0.8\", \"0.85\", \"0.9\", \"0.95\"]\n",
    "        #else:\n",
    "        #r_targets = [\"0.8\", \"0.85\", \"0.9\", \"0.95\", \"0.99\"]\n",
    "        r_targets = [\"0.95\"]\n",
    "\n",
    "        for ir, r_target in enumerate(r_targets):\n",
    "            ipi = interval_conf[ds_name][k][r_target][\"ipi\"]\n",
    "            mpi = interval_conf[ds_name][k][r_target][\"mpi\"]\n",
    "            r_target = float(r_target)\n",
    "                        \n",
    "            no_early_termination_df = pd.read_csv(get_plain_ivf_results_path(ds_name, k, nlist, nprobe, s), usecols=[\"qid\", \"step\", \"dists\", \"inserts\", \"elaps_ms\", \"r\"])\n",
    "            baseline_mean = no_early_termination_df[\"elaps_ms\"].mean()\n",
    "            darth_df = pd.read_csv(get_darth_results_path(ds_name, k, nlist, nprobe, s, r_target, ipi, mpi), usecols=[\"qid\", \"step\", \"dists\", \"inserts\", \"elaps_ms\", \"r_actual\", \"r_predicted\", \"r_predictor_calls\", \"r_predictor_time_ms\",])\n",
    "            elapsed_mean = darth_df[\"elaps_ms\"].mean()\n",
    "            predictor_calls_mean = darth_df[\"r_predictor_calls\"].mean()\n",
    "            no_early_termination_df = no_early_termination_df[no_early_termination_df[\"r\"] >= r_target]\n",
    "            darth_df = darth_df[darth_df[\"qid\"].isin(no_early_termination_df[\"qid\"])]\n",
    "            \n",
    "            fig_recall, ax_recall = plt.subplots(figsize=(8, 4))\n",
    "            ax_recall.hist(darth_df[\"r_actual\"], alpha=0.8, color=\"tomato\", edgecolor=\"black\", linewidth=2.0)\n",
    "            r_actual_mean = darth_df[\"r_actual\"].mean()\n",
    "            ax_recall.axvline(r_actual_mean, color=\"tomato\", linestyle=\"dashed\", linewidth=4, label=f\"DARTH avg:{r_actual_mean:.2f}\")\n",
    "            ax_recall.axvline(r_target, color=\"black\", linestyle=\"dashed\", linewidth=4, label=r\"$R_t$\")\n",
    "            for spine in ax_recall.spines.values():\n",
    "                spine.set_visible(False)\n",
    "            \n",
    "            #ax_recall.set_yscale(\"log\")\n",
    "            ax_recall.set_ylabel(\"# Queries\")\n",
    "            ax_recall.set_xlabel(f\"Actual Recall\")\n",
    "            ax_recall.grid(alpha=0.8, linestyle=\"--\")\n",
    "            ax_recall.legend(fontsize=24)\n",
    "            fig_recall.savefig(f\"{PLOTS_DIR}perf_recall_{ds_name}_k{k}_{r_target}.pdf\", bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "            plt.close(fig_recall)\n",
    "            \n",
    "            #fig_predictor_calls, ax_predictor_calls = plt.subplots(figsize=(8, 4))\n",
    "            #ax_predictor_calls.hist(darth_df[\"r_predictor_calls\"], alpha=0.8, color=\"tomato\", edgecolor=\"black\", linewidth=2.0)\n",
    "            #ax_predictor_calls.axvline(predictor_calls_mean, color=\"tomato\", linestyle=\"dashed\", linewidth=4, label=f\"DARTH avg:{round(predictor_calls_mean)}\")\n",
    "            #for spine in ax_predictor_calls.spines.values():\n",
    "            #    spine.set_visible(False)\n",
    "            #ax_predictor_calls.set_ylabel(\"# Queries\")\n",
    "            #ax_predictor_calls.set_xlabel(\"Predictor Calls\")\n",
    "            #ax_predictor_calls.grid(alpha=0.8, linestyle=\"--\")\n",
    "            #ax_predictor_calls.legend(fontsize=24)\n",
    "            #fig_predictor_calls.savefig(f\"{PLOTS_DIR}perf_predictor_calls_{ds_name}_k{k}_{r_target}.pdf\", bbox_inches=\"tight\")\n",
    "            #plt.show()\n",
    "            #plt.close(fig_predictor_calls)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1000\n",
    "all_datasets = [\"SIFT100M\", \"DEEP100M\", \"GLOVE100\", \"GIST1M\"]\n",
    "all_k_values = [\"50\"]\n",
    "for ds_name in all_datasets:\n",
    "    for k in all_k_values:\n",
    "        nlist = dataset_params[ds_name][\"nlist\"]\n",
    "        nprobe = dataset_params[ds_name][\"nprobe\"]\n",
    "        li = dataset_params[ds_name][\"ivf_li\"]\n",
    "        \n",
    "        no_early_termination_df = pd.read_csv(get_plain_ivf_results_path(ds_name, k, nlist, nprobe, s), usecols=[\"qid\", \"step\", \"dists\", \"inserts\", \"elaps_ms\", \"r\"])\n",
    "        plain_ivf_avg_recall = no_early_termination_df[\"r\"].mean()\n",
    "        print(f\"{ds_name} k={k} plain ivf avg recall: {plain_ivf_avg_recall:.3f}\")\n",
    "\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localPyLibs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
