{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split  # type: ignore\n",
    "from sklearn.linear_model import LinearRegression  # type: ignore\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def get_dataset_name(M, efC, efS, num_queries, ds_name, k, logint):\n",
    "    return f\"/data/mchatzakis/et_training_data/early-stop-training/{ds_name}/k{k}/M{M}_efC{efC}_efS{efS}_qs{num_queries}_li{logint}.txt\"\n",
    "\n",
    "\n",
    "dataset_params = {\n",
    "        \"SIFT100M\": {\n",
    "            \"M\": 32,\n",
    "            \"efC\": 500,\n",
    "            \"efS\": 500,\n",
    "            \"d\": 128,\n",
    "        },\n",
    "        \"GIST1M\": {\n",
    "            \"M\": 32,\n",
    "            \"efC\": 500,\n",
    "            \"efS\": 1000,\n",
    "            \"d\": 960,\n",
    "        },\n",
    "        \"GLOVE100\": {\n",
    "            \"M\": 16,\n",
    "            \"efC\": 500,\n",
    "            \"efS\": 500,\n",
    "            \"d\": 100,\n",
    "        },\n",
    "        \"DEEP100M\": {\n",
    "            \"M\": 32,\n",
    "            \"efC\": 500,\n",
    "            \"efS\": 750,\n",
    "            \"d\": 96,\n",
    "        },\n",
    "}\n",
    "    \n",
    "def get_dataset_name(M, efC, efS, num_queries, ds_name, k, logint):\n",
    "    return f\"/data/mchatzakis/et_training_data/early-stop-training/{ds_name}/k{k}/M{M}_efC{efC}_efS{efS}_qs{num_queries}_li{logint}.txt\"\n",
    "\n",
    "def get_validation_dataset_name(M, efC, efS, query_num, ds_name, k, logint): \n",
    "    return f\"../../experiments/results/validation_logging/{ds_name}/k{k}/M{M}_efC{efC}_efS{efS}_qs{query_num}_li{logint}.txt\"\n",
    "\n",
    "index_metric_feats = [\"step\", \"dists\", \"inserts\"]\n",
    "neighbor_distances_feats = [\"first_nn_dist\", \"nn_dist\", \"furthest_dist\"]\n",
    "neighbor_stats_feats = [\"avg_dist\", \"variance\", \"percentile_25\", \"percentile_50\", \"percentile_75\"]\n",
    "    \n",
    "all_feats = index_metric_feats + neighbor_distances_feats + neighbor_stats_feats\n",
    "\n",
    "columns_to_load = [\"qid\", \"elaps_ms\"] + all_feats + [\"r\", \"feats_collect_time_ms\"]\n",
    "    \n",
    "feature_classes = {\n",
    "    \"all_feats\": all_feats,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_predictors(ds_name, k):  \n",
    "    li = 1\n",
    "    s = 10000\n",
    "    M = dataset_params[ds_name][\"M\"]\n",
    "    efC = dataset_params[ds_name][\"efC\"]\n",
    "    efS = dataset_params[ds_name][\"efS\"]\n",
    "    d = dataset_params[ds_name][\"d\"]\n",
    "    \n",
    "    data_path = get_dataset_name(M, efC, efS, s, ds_name, k, li)\n",
    "    print(f\"{ds_name} | k={k} | Path: {data_path}\")\n",
    "            \n",
    "    all_queries_dask = dd.read_csv(data_path, usecols=columns_to_load)\n",
    "    all_queries_data = all_queries_dask.compute()\n",
    "            \n",
    "    assert all_queries_data[\"qid\"].nunique() == s, f\"Expected {s} queries, got {all_queries_data['qid'].nunique()}\"\n",
    "            \n",
    "    query_data_all = all_queries_data[all_queries_data[\"qid\"] < s]               \n",
    "                        \n",
    "    data_all = query_data_all[query_data_all[\"dists\"] % li == 0]\n",
    "                        \n",
    "    print(f\"    {s} Queries Data Shape: {data_all.shape} |  Unique queries: {data_all['qid'].nunique()} | Li: {li}\")                \n",
    "                    \n",
    "    assert data_all[\"qid\"].nunique() == s, f\"Expected {s} queries, got {data_all['qid'].nunique()}\"\n",
    "    assert data_all.shape[1] == len(columns_to_load), f\"Expected {len(columns_to_load) + d} columns, got {data_all.shape[1]}\"\n",
    "                                \n",
    "    y_all = data_all[\"r\"]\n",
    "                        \n",
    "    feats = feature_classes[\"all_feats\"]\n",
    "                                                    \n",
    "    X_all = data_all[feats]\n",
    "    X_train, y_train = X_all, y_all\n",
    "                        \n",
    "    print(f\"    X_train shape: {X_train.shape} | y_train shape: {y_train.shape}\")\n",
    "\n",
    "    trained_models = {}\n",
    "\n",
    "    n_estimators = 100\n",
    "    learning_rate = 0.1\n",
    "    reg_lambda = 0.0\n",
    "    ml_models = {\n",
    "        #\"RandomForest\": RandomForestRegressor(n_estimators=n_estimators, random_state=SEED),\n",
    "        #\"DecisionTree\": DecisionTreeRegressor(random_state=SEED),\n",
    "        \"LGBM\": lgb.LGBMRegressor(objective='regression', random_state=SEED, n_estimators=n_estimators, verbose = -1, learning_rate=learning_rate, reg_lambda=reg_lambda),\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "    }\n",
    "\n",
    "    for model_name, model in ml_models.items():\n",
    "        print(f\"        Training {model_name}...\")\n",
    "        model_train_time_start = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        model_train_time = time.time() - model_train_time_start\n",
    "        trained_models[model_name] = model\n",
    "        print(f\"        {model_name} | Training Time: {model_train_time}\")     \n",
    "\n",
    "    validation_data_dd = dd.read_csv(get_validation_dataset_name(M, efC, efS, 1000, ds_name, k, 1), usecols=columns_to_load)\n",
    "    validation_data_df = validation_data_dd.compute()\n",
    "            \n",
    "    validation_y_true = validation_data_df[\"r\"]\n",
    "            \n",
    "    print(f\"    Validation data shape: {validation_data_df.shape}\")\n",
    "\n",
    "    feats = feature_classes[\"all_feats\"]\n",
    "    validation_X = validation_data_df[feats]\n",
    "\n",
    "    model_results = {}\n",
    "    \n",
    "    for model_name, model in trained_models.items():\n",
    "        validation_y_pred = model.predict(validation_X)\n",
    "        mse = mean_squared_error(validation_y_true, validation_y_pred)\n",
    "        mae = mean_absolute_error(validation_y_true, validation_y_pred)\n",
    "        r2 = r2_score(validation_y_true, validation_y_pred)\n",
    "        \n",
    "        model_results[model_name] = {\n",
    "            \"mse\": mse,\n",
    "            \"mae\": mae,\n",
    "            \"r2\": r2,\n",
    "        }\n",
    "        \n",
    "        print(f\"        {model_name} | MSE: {mse:.4f} | MAE: {mae:.4f} | R2: {r2:.2f}\")\n",
    "        \n",
    "    return model_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ds_names = [\"GIST1M\", \"DEEP100M\", \"SIFT100M\"]\n",
    "all_k = [10, 25, 50, 75, 100]\n",
    "\n",
    "for ds_name in all_ds_names:\n",
    "    ds_results = {}\n",
    "    for k in all_k:\n",
    "        ds_results[k] = compare_predictors(ds_name, k)\n",
    "    \n",
    "    # We have to calculate the averages across all k for each model\n",
    "    for model_name in ds_results[all_k[0]]:\n",
    "        model_results = ds_results[all_k[0]][model_name]\n",
    "        for k in all_k[1:]:\n",
    "            model_results[\"mse\"] += ds_results[k][model_name][\"mse\"]\n",
    "            model_results[\"mae\"] += ds_results[k][model_name][\"mae\"]\n",
    "            model_results[\"r2\"] += ds_results[k][model_name][\"r2\"]\n",
    "        \n",
    "        model_results[\"mse\"] /= len(all_k)\n",
    "        model_results[\"mae\"] /= len(all_k)\n",
    "        model_results[\"r2\"] /= len(all_k)\n",
    "        \n",
    "        print(f\"{ds_name} | {model_name} | MSE: {model_results['mse']:.4f} | MAE: {model_results['mae']:.4f} | R2: {model_results['r2']:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localPyLibs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
